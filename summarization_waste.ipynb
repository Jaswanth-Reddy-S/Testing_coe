{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "NLP1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a56def3cffd41c59b97cf30707961b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_244f037c04ba4cb9939016d7f673972f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_50e7e7781f3c44598e0d6da235b78708",
              "IPY_MODEL_0693e55bfff54be085081a75cef3a98c"
            ]
          }
        },
        "244f037c04ba4cb9939016d7f673972f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50e7e7781f3c44598e0d6da235b78708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_694e7399383e4dceb3e0192373c7e652",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a8eb1495fda412784516551930103f1"
          }
        },
        "0693e55bfff54be085081a75cef3a98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4adc9760e3843b385b344d695bbc672",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:09&lt;00:00, 46.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_563a5db7c5ed456abc6e43892b6d7554"
          }
        },
        "694e7399383e4dceb3e0192373c7e652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a8eb1495fda412784516551930103f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4adc9760e3843b385b344d695bbc672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "563a5db7c5ed456abc6e43892b6d7554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96c0bada7f124636b1b165daf7895d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e20326a1b6324d899782b3efbda2d1ac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3858c4e9edf4f1a8f306f0672dc20c6",
              "IPY_MODEL_1d42440584f14e4da0bd37db4b4c6a24"
            ]
          }
        },
        "e20326a1b6324d899782b3efbda2d1ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3858c4e9edf4f1a8f306f0672dc20c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9e055ec07d746ad80fded510029c67e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd54f392bdfd4bc395a5b965fc0d1cb3"
          }
        },
        "1d42440584f14e4da0bd37db4b4c6a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0280e6b6a04451aac1df51e341cedc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 992kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cbb25ad202e4f148056627ddd459bcc"
          }
        },
        "a9e055ec07d746ad80fded510029c67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd54f392bdfd4bc395a5b965fc0d1cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0280e6b6a04451aac1df51e341cedc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cbb25ad202e4f148056627ddd459bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ee977c63792460f988281ac6c209b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4df984f30a1041bfa72082fa5229d60f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a441aeba2eef4fa2b167e9d635adf3f3",
              "IPY_MODEL_c656e91f25874a319373fda149cbf67b"
            ]
          }
        },
        "4df984f30a1041bfa72082fa5229d60f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a441aeba2eef4fa2b167e9d635adf3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24bdcad8803846c98eae377bf9152e4b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a12a7715cb9e452498bcd61ac82ab24e"
          }
        },
        "c656e91f25874a319373fda149cbf67b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d9287d6de704596aac0cd7d5bba2a3b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 3.52MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b90818ded77410b9fb0f30fea541588"
          }
        },
        "24bdcad8803846c98eae377bf9152e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a12a7715cb9e452498bcd61ac82ab24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d9287d6de704596aac0cd7d5bba2a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b90818ded77410b9fb0f30fea541588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4bc04ed2d8e4ccfabcc4f7a4c2bfb8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6338916d3104db599555cb735dd35a4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1fc2e1a35b8146ba9f4cd3bde029c347",
              "IPY_MODEL_435441751fce4a2a811d8fbf228e5269"
            ]
          }
        },
        "f6338916d3104db599555cb735dd35a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fc2e1a35b8146ba9f4cd3bde029c347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2c99d3f0a1c47cba601a9021af0e11b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec81d22b2fef44d383ea895270289070"
          }
        },
        "435441751fce4a2a811d8fbf228e5269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6720fb4dcb4c4246847411265645f56f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:08&lt;00:00, 3.14B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d97bf396f7594fce8d57f2f1eee5eb8b"
          }
        },
        "b2c99d3f0a1c47cba601a9021af0e11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec81d22b2fef44d383ea895270289070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6720fb4dcb4c4246847411265645f56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d97bf396f7594fce8d57f2f1eee5eb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04312f41451c4ed18b7aa8ff62765b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3150521bbc824722b998733b6f56a175",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_15abc97409ce4e519821c1917b5e1bfe",
              "IPY_MODEL_cc5012994c814f549990f7c4de7430f3"
            ]
          }
        },
        "3150521bbc824722b998733b6f56a175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15abc97409ce4e519821c1917b5e1bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80eeefb61e85422fb53a12625334c375",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30ecdc14f9e546328711966ed9def3f4"
          }
        },
        "cc5012994c814f549990f7c4de7430f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc1c7334f58d4d6ca32802e91245c622",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 54.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8f394d82151458aac9ef174baa5f1c4"
          }
        },
        "80eeefb61e85422fb53a12625334c375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30ecdc14f9e546328711966ed9def3f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc1c7334f58d4d6ca32802e91245c622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8f394d82151458aac9ef174baa5f1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_wtMI20yaOG"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruZ2Ue3EywLa",
        "outputId": "5c0002d8-fae4-4032-e3b2-994dd81398fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip /content/utils_nlp.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/utils_nlp.zip\n",
            "  inflating: utils_nlp/__init__.py   \n",
            "   creating: utils_nlp/azureml/\n",
            " extracting: utils_nlp/azureml/__init__.py  \n",
            "  inflating: utils_nlp/azureml/azureml_bert_util.py  \n",
            "  inflating: utils_nlp/azureml/azureml_utils.py  \n",
            "  inflating: utils_nlp/azureml/README.md  \n",
            "   creating: utils_nlp/common/\n",
            " extracting: utils_nlp/common/__init__.py  \n",
            "  inflating: utils_nlp/common/pytorch_utils.py  \n",
            "  inflating: utils_nlp/common/README.md  \n",
            "  inflating: utils_nlp/common/timer.py  \n",
            "   creating: utils_nlp/dataset/\n",
            "  inflating: utils_nlp/dataset/__init__.py  \n",
            "  inflating: utils_nlp/dataset/bbc_hindi.py  \n",
            "  inflating: utils_nlp/dataset/cnndm.py  \n",
            "  inflating: utils_nlp/dataset/dac.py  \n",
            "  inflating: utils_nlp/dataset/data_loaders.py  \n",
            "  inflating: utils_nlp/dataset/msrpc.py  \n",
            "  inflating: utils_nlp/dataset/multinli.py  \n",
            "  inflating: utils_nlp/dataset/ner_utils.py  \n",
            "  inflating: utils_nlp/dataset/preprocess.py  \n",
            "  inflating: utils_nlp/dataset/README.md  \n",
            "  inflating: utils_nlp/dataset/sentence_selection.py  \n",
            "  inflating: utils_nlp/dataset/snli.py  \n",
            "  inflating: utils_nlp/dataset/squad.py  \n",
            "  inflating: utils_nlp/dataset/stsbenchmark.py  \n",
            "  inflating: utils_nlp/dataset/url_utils.py  \n",
            "  inflating: utils_nlp/dataset/wikigold.py  \n",
            "  inflating: utils_nlp/dataset/xnli.py  \n",
            "  inflating: utils_nlp/dataset/xnli_torch_dataset.py  \n",
            "   creating: utils_nlp/eval/\n",
            "  inflating: utils_nlp/eval/__init__.py  \n",
            "  inflating: utils_nlp/eval/classification.py  \n",
            "  inflating: utils_nlp/eval/evaluate_squad.py  \n",
            "  inflating: utils_nlp/eval/evaluate_summarization.py  \n",
            "  inflating: utils_nlp/eval/question_answering.py  \n",
            "  inflating: utils_nlp/eval/README.md  \n",
            "   creating: utils_nlp/eval/rouge/\n",
            "  inflating: utils_nlp/eval/rouge/compute_rouge.py  \n",
            "  inflating: utils_nlp/eval/rouge/rouge_ext.py  \n",
            "  inflating: utils_nlp/eval/senteval.py  \n",
            "   creating: utils_nlp/eval/SentEval/\n",
            "  inflating: utils_nlp/eval/SentEval/.gitignore  \n",
            "   creating: utils_nlp/eval/SentEval/data/\n",
            "   creating: utils_nlp/eval/SentEval/data/downstream/\n",
            "  inflating: utils_nlp/eval/SentEval/data/downstream/get_transfer_data.bash  \n",
            "  inflating: utils_nlp/eval/SentEval/data/downstream/tokenizer.sed  \n",
            "  inflating: utils_nlp/eval/SentEval/LICENSE  \n",
            "  inflating: utils_nlp/eval/SentEval/README.md  \n",
            "   creating: utils_nlp/eval/SentEval/senteval/\n",
            "  inflating: utils_nlp/eval/SentEval/senteval/__init__.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/binary.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/engine.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/mrpc.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/probing.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/rank.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/sick.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/snli.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/sst.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/sts.py  \n",
            "   creating: utils_nlp/eval/SentEval/senteval/tools/\n",
            " extracting: utils_nlp/eval/SentEval/senteval/tools/__init__.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/tools/classifier.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/tools/ranking.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/tools/relatedness.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/tools/validation.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/trec.py  \n",
            "  inflating: utils_nlp/eval/SentEval/senteval/utils.py  \n",
            "  inflating: utils_nlp/eval/SentEval/setup.py  \n",
            "   creating: utils_nlp/interpreter/\n",
            " extracting: utils_nlp/interpreter/__init__.py  \n",
            "  inflating: utils_nlp/interpreter/Interpreter.py  \n",
            "  inflating: utils_nlp/interpreter/README.md  \n",
            "   creating: utils_nlp/language_utils/\n",
            "   creating: utils_nlp/language_utils/hi/\n",
            "  inflating: utils_nlp/language_utils/hi/hindi_stemmer.py  \n",
            "   creating: utils_nlp/models/\n",
            "   creating: utils_nlp/models/bert/\n",
            " extracting: utils_nlp/models/bert/__init__.py  \n",
            "  inflating: utils_nlp/models/bert/common.py  \n",
            "  inflating: utils_nlp/models/bert/README.md  \n",
            "  inflating: utils_nlp/models/bert/sequence_classification.py  \n",
            "  inflating: utils_nlp/models/bert/sequence_classification_distributed.py  \n",
            "  inflating: utils_nlp/models/bert/sequence_encoding.py  \n",
            "  inflating: utils_nlp/models/bert/token_classification.py  \n",
            "   creating: utils_nlp/models/gensen/\n",
            "  inflating: utils_nlp/models/gensen/__init__.py  \n",
            "  inflating: utils_nlp/models/gensen/create_gensen_model.py  \n",
            "  inflating: utils_nlp/models/gensen/gensen.py  \n",
            "  inflating: utils_nlp/models/gensen/multi_task_model.py  \n",
            "  inflating: utils_nlp/models/gensen/preprocess_utils.py  \n",
            "  inflating: utils_nlp/models/gensen/README.md  \n",
            "  inflating: utils_nlp/models/gensen/utils.py  \n",
            "   creating: utils_nlp/models/glove/\n",
            "  inflating: utils_nlp/models/glove/demo.sh  \n",
            "  inflating: utils_nlp/models/glove/Makefile  \n",
            "  inflating: utils_nlp/models/glove/README.md  \n",
            "   creating: utils_nlp/models/glove/src/\n",
            "  inflating: utils_nlp/models/glove/src/cooccur.c  \n",
            "  inflating: utils_nlp/models/glove/src/glove.c  \n",
            "  inflating: utils_nlp/models/glove/src/README.md  \n",
            "  inflating: utils_nlp/models/glove/src/shuffle.c  \n",
            "  inflating: utils_nlp/models/glove/src/vocab_count.c  \n",
            "   creating: utils_nlp/models/pretrained_embeddings/\n",
            "  inflating: utils_nlp/models/pretrained_embeddings/__init__.py  \n",
            "  inflating: utils_nlp/models/pretrained_embeddings/fasttext.py  \n",
            "  inflating: utils_nlp/models/pretrained_embeddings/glove.py  \n",
            "  inflating: utils_nlp/models/pretrained_embeddings/README.md  \n",
            "  inflating: utils_nlp/models/pretrained_embeddings/word2vec.py  \n",
            "   creating: utils_nlp/models/pytorch_modules/\n",
            "  inflating: utils_nlp/models/pytorch_modules/__init__.py  \n",
            "  inflating: utils_nlp/models/pytorch_modules/conditional_gru.py  \n",
            "  inflating: utils_nlp/models/pytorch_modules/README.md  \n",
            "  inflating: utils_nlp/models/README.md  \n",
            "   creating: utils_nlp/models/transformers/\n",
            "  inflating: utils_nlp/models/transformers/abstractive_summarization_bertsum.py  \n",
            "  inflating: utils_nlp/models/transformers/abstractive_summarization_seq2seq.py  \n",
            "   creating: utils_nlp/models/transformers/bertsum/\n",
            " extracting: utils_nlp/models/transformers/bertsum/__init__.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/adam.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/beam.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/data_loader.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/dataset.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/decoder.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/encoder.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/loss.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/model_builder.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/neural.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/optimizers.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/penalties.py  \n",
            "  inflating: utils_nlp/models/transformers/bertsum/predictor.py  \n",
            "  inflating: utils_nlp/models/transformers/common.py  \n",
            "  inflating: utils_nlp/models/transformers/datasets.py  \n",
            "  inflating: utils_nlp/models/transformers/extractive_summarization.py  \n",
            "  inflating: utils_nlp/models/transformers/named_entity_recognition.py  \n",
            "  inflating: utils_nlp/models/transformers/question_answering.py  \n",
            "  inflating: utils_nlp/models/transformers/sequence_classification.py  \n",
            "   creating: utils_nlp/models/xlnet/\n",
            "  inflating: utils_nlp/models/xlnet/common.py  \n",
            "  inflating: utils_nlp/models/xlnet/README.md  \n",
            "  inflating: utils_nlp/models/xlnet/sequence_classification.py  \n",
            "  inflating: utils_nlp/README.md     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nlMJso7y5EN"
      },
      "source": [
        "QUICK_RUN = True\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bz4KblazSXK"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "from tempfile import TemporaryDirectory\n",
        "import torch\n",
        "\n",
        "nlp_path = os.path.abspath(\"../../\")\n",
        "if nlp_path not in sys.path:\n",
        "    sys.path.insert(0, nlp_path)\n",
        "\n",
        "from utils_nlp.models.transformers.abstractive_summarization_bertsum import (\n",
        "    BertSumAbs,\n",
        "    BertSumAbsProcessor,\n",
        ")\n",
        "\n",
        "from utils_nlp.dataset.cnndm import CNNDMSummarizationDataset\n",
        "from utils_nlp.eval import compute_rouge_python\n",
        "\n",
        "from utils_nlp.models.transformers.datasets import SummarizationDataset\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import pprint\n",
        "import scrapbook as sb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE9urVZVzUuw"
      },
      "source": [
        "#pip install scrapbook"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbAmWDJezYyK"
      },
      "source": [
        "#pip install indic-nlp-library"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFfP1ZMmzuFZ"
      },
      "source": [
        "# the data path used to save the downloaded data file\n",
        "DATA_PATH = TemporaryDirectory().name\n",
        "# The number of lines at the head of data file used for preprocessing. -1 means all the lines.\n",
        "TOP_N = 100\n",
        "if not QUICK_RUN:\n",
        "    TOP_N = -1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEQgwKcJ0RBI",
        "outputId": "7cfbd9bd-1b36-43dd-c847-6d57f158701b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset, test_dataset = CNNDMSummarizationDataset(\n",
        "    top_n=TOP_N, local_cache_path=DATA_PATH, prepare_extractive=False\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 489k/489k [00:07<00:00, 62.4kKB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1eacFDU0TGV",
        "outputId": "2f422e36-bb97-4717-f731-dbe95bebf232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_dataset)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJsvfon00Uxn",
        "outputId": "4992f68e-2cf7-49a3-c35f-65356a743660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(test_dataset)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQMFnLm0WY2"
      },
      "source": [
        "\n",
        "# notebook parameters\n",
        "# the cache path\n",
        "CACHE_PATH = TemporaryDirectory().name\n",
        "\n",
        "# model parameters\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "MAX_POS = 512\n",
        "MAX_SOURCE_SEQ_LENGTH = 440\n",
        "MAX_TARGET_SEQ_LENGTH = 72\n",
        "\n",
        "# mixed precision setting. To enable mixed precision training, follow instructions in SETUP.md.\n",
        "FP16 = False\n",
        "if FP16:\n",
        "    FP16_OPT_LEVEL = \"O2\"\n",
        "\n",
        "# fine-tuning parameters\n",
        "# batch size, unit is the number of tokens\n",
        "BATCH_SIZE_PER_GPU = 1\n",
        "\n",
        "\n",
        "# GPU used for training\n",
        "NUM_GPUS = torch.cuda.device_count()\n",
        "if NUM_GPUS > 0:\n",
        "    BATCH_SIZE = NUM_GPUS * BATCH_SIZE_PER_GPU\n",
        "else:\n",
        "    BATCH_SIZE = 1\n",
        "\n",
        "\n",
        "# Learning rate\n",
        "LEARNING_RATE_BERT = 5e-4 / 2.0\n",
        "LEARNING_RATE_DEC = 0.05 / 2.0\n",
        "\n",
        "\n",
        "# How often the statistics reports show up in training, unit is step.\n",
        "REPORT_EVERY = 10\n",
        "SAVE_EVERY = 500\n",
        "\n",
        "# total number of steps for training\n",
        "MAX_STEPS = 1e3\n",
        "\n",
        "if not QUICK_RUN:\n",
        "    MAX_STEPS = 5e3\n",
        "\n",
        "WARMUP_STEPS_BERT = 2000\n",
        "WARMUP_STEPS_DEC = 1000"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0we2gAp0aDF",
        "outputId": "afae5cc8-9c0a-417f-e7f3-c721e51398fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "1a56def3cffd41c59b97cf30707961b9",
            "244f037c04ba4cb9939016d7f673972f",
            "50e7e7781f3c44598e0d6da235b78708",
            "0693e55bfff54be085081a75cef3a98c",
            "694e7399383e4dceb3e0192373c7e652",
            "9a8eb1495fda412784516551930103f1",
            "f4adc9760e3843b385b344d695bbc672",
            "563a5db7c5ed456abc6e43892b6d7554",
            "96c0bada7f124636b1b165daf7895d9c",
            "e20326a1b6324d899782b3efbda2d1ac",
            "c3858c4e9edf4f1a8f306f0672dc20c6",
            "1d42440584f14e4da0bd37db4b4c6a24",
            "a9e055ec07d746ad80fded510029c67e",
            "dd54f392bdfd4bc395a5b965fc0d1cb3",
            "f0280e6b6a04451aac1df51e341cedc9",
            "4cbb25ad202e4f148056627ddd459bcc",
            "5ee977c63792460f988281ac6c209b71",
            "4df984f30a1041bfa72082fa5229d60f",
            "a441aeba2eef4fa2b167e9d635adf3f3",
            "c656e91f25874a319373fda149cbf67b",
            "24bdcad8803846c98eae377bf9152e4b",
            "a12a7715cb9e452498bcd61ac82ab24e",
            "4d9287d6de704596aac0cd7d5bba2a3b",
            "3b90818ded77410b9fb0f30fea541588",
            "a4bc04ed2d8e4ccfabcc4f7a4c2bfb8c",
            "f6338916d3104db599555cb735dd35a4",
            "1fc2e1a35b8146ba9f4cd3bde029c347",
            "435441751fce4a2a811d8fbf228e5269",
            "b2c99d3f0a1c47cba601a9021af0e11b",
            "ec81d22b2fef44d383ea895270289070",
            "6720fb4dcb4c4246847411265645f56f",
            "d97bf396f7594fce8d57f2f1eee5eb8b",
            "04312f41451c4ed18b7aa8ff62765b0c",
            "3150521bbc824722b998733b6f56a175",
            "15abc97409ce4e519821c1917b5e1bfe",
            "cc5012994c814f549990f7c4de7430f3",
            "80eeefb61e85422fb53a12625334c375",
            "30ecdc14f9e546328711966ed9def3f4",
            "bc1c7334f58d4d6ca32802e91245c622",
            "d8f394d82151458aac9ef174baa5f1c4"
          ]
        }
      },
      "source": [
        "# processor which contains the colloate function to load the preprocessed data\n",
        "processor = BertSumAbsProcessor(cache_dir=CACHE_PATH, max_src_len=MAX_SOURCE_SEQ_LENGTH, max_tgt_len=MAX_TARGET_SEQ_LENGTH)\n",
        "# summarizer\n",
        "summarizer = BertSumAbs(\n",
        "    processor, cache_dir=CACHE_PATH, max_pos_length=MAX_POS\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a56def3cffd41c59b97cf30707961b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96c0bada7f124636b1b165daf7895d9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ee977c63792460f988281ac6c209b71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4bc04ed2d8e4ccfabcc4f7a4c2bfb8c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04312f41451c4ed18b7aa8ff62765b0c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhbWU1LC0chX",
        "outputId": "40cb0d80-9f32-4067-b9ec-c2d924067008",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "BATCH_SIZE_PER_GPU*NUM_GPUS\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKjrrl3X0eVh",
        "outputId": "390d9a69-5ade-4c3b-94ff-d8f739f052e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summarizer.fit(\n",
        "    train_dataset,\n",
        "    num_gpus=NUM_GPUS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    max_steps=MAX_STEPS,\n",
        "    learning_rate_bert=LEARNING_RATE_BERT,\n",
        "    learning_rate_dec=LEARNING_RATE_DEC,\n",
        "    warmup_steps_bert=WARMUP_STEPS_BERT,\n",
        "    warmup_steps_dec=WARMUP_STEPS_DEC,\n",
        "    save_every=SAVE_EVERY,\n",
        "    report_every=REPORT_EVERY * 5,\n",
        "    fp16=FP16,\n",
        "    # checkpoint=\"saved checkpoint path\"\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device is cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:12<00:12,  3.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:30:18, average loss: 10.950929, time duration: 12.732745,\n",
            "                            number of examples in current reporting: 50, step 50\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:25<00:00,  3.90it/s]\n",
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:30:31, average loss: 6.530313, time duration: 12.882334,\n",
            "                            number of examples in current reporting: 50, step 100\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:30:44, average loss: 5.400981, time duration: 13.097159,\n",
            "                            number of examples in current reporting: 50, step 150\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.78it/s]\n",
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:30:58, average loss: 5.167683, time duration: 13.336613,\n",
            "                            number of examples in current reporting: 50, step 200\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:31:11, average loss: 4.811103, time duration: 13.488808,\n",
            "                            number of examples in current reporting: 50, step 250\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.72it/s]\n",
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:31:25, average loss: 4.739688, time duration: 13.430566,\n",
            "                            number of examples in current reporting: 50, step 300\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:31:38, average loss: 4.351925, time duration: 13.281558,\n",
            "                            number of examples in current reporting: 50, step 350\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.77it/s]\n",
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:31:51, average loss: 4.322100, time duration: 13.256587,\n",
            "                            number of examples in current reporting: 50, step 400\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:32:04, average loss: 3.614549, time duration: 13.231083,\n",
            "                            number of examples in current reporting: 50, step 450\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:26<00:00,  3.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:32:18, average loss: 3.728737, time duration: 13.221491,\n",
            "                            number of examples in current reporting: 50, step 500\n",
            "                            out of total 1000\n",
            "saving through pytorch to /tmp/tmp59jh8age/fine_tuned/bertsumabs.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:51<00:00,  1.96it/s]\n",
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:32:55, average loss: 2.907764, time duration: 37.954973,\n",
            "                            number of examples in current reporting: 50, step 550\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.72it/s]\n",
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:33:09, average loss: 3.195182, time duration: 13.598862,\n",
            "                            number of examples in current reporting: 50, step 600\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:33:23, average loss: 2.380251, time duration: 13.707165,\n",
            "                            number of examples in current reporting: 50, step 650\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:27<00:00,  3.70it/s]\n",
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:33:36, average loss: 2.491098, time duration: 13.354024,\n",
            "                            number of examples in current reporting: 50, step 700\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:33:49, average loss: 1.741870, time duration: 13.233144,\n",
            "                            number of examples in current reporting: 50, step 750\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.78it/s]\n",
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:34:03, average loss: 2.084065, time duration: 13.216777,\n",
            "                            number of examples in current reporting: 50, step 800\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:34:16, average loss: 1.573089, time duration: 13.213495,\n",
            "                            number of examples in current reporting: 50, step 850\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:26<00:00,  3.78it/s]\n",
            "Iteration:   0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:34:29, average loss: 1.752107, time duration: 13.251715,\n",
            "                            number of examples in current reporting: 50, step 900\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:13<00:13,  3.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:34:42, average loss: 1.302017, time duration: 13.338566,\n",
            "                            number of examples in current reporting: 50, step 950\n",
            "                            out of total 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:26<00:00,  3.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "timestamp: 16/04/2021 06:34:56, average loss: 1.628928, time duration: 13.365089,\n",
            "                            number of examples in current reporting: 50, step 1000\n",
            "                            out of total 1000\n",
            "saving through pytorch to /tmp/tmp59jh8age/fine_tuned/bertsumabs.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:52<00:00,  1.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "saving through pytorch to /tmp/tmp59jh8age/fine_tuned/bertsumabs.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWrOuw2J0gYC",
        "outputId": "4fe378a2-3bf8-4040-ab17-5c3fd7654b3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "summarizer.save_model(MAX_STEPS, os.path.join(CACHE_PATH, \"bertsumabs.pt\"))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/tmp59jh8age\n",
            "saving through pytorch to /tmp/tmp59jh8age/bertsumabs.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh4vJiwv7dp_",
        "outputId": "27404535-df94-432b-bbc9-e5e790625c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "CACHE_PATH"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/tmp/tmp59jh8age'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zha8d8QoAFK9"
      },
      "source": [
        "checkpoint = torch.load(os.path.join(CACHE_PATH, \"bertsumabs.pt\"), map_location=\"cpu\")\n",
        "summarizer = BertSumAbs(\n",
        "    processor, cache_dir=CACHE_PATH, max_pos_length=MAX_POS, test=True\n",
        ")\n",
        "summarizer.model.load_checkpoint(checkpoint['model'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9-iesnf7TLz"
      },
      "source": [
        "TEST_TOP_N = 32\n",
        "if not QUICK_RUN:\n",
        "    TEST_TOP_N = len(test_dataset)\n",
        "\n",
        "if NUM_GPUS:\n",
        "    BATCH_SIZE = NUM_GPUS * BATCH_SIZE_PER_GPU\n",
        "else:\n",
        "    BATCH_SIZE = 1\n",
        "    \n",
        "shortened_dataset = test_dataset.shorten(top_n=TEST_TOP_N)\n",
        "src = shortened_dataset.get_source()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBU2au6I_Hsm",
        "outputId": "7155b19e-e63a-4fff-c5d3-2695e7fb0d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "reference_summaries = [\" \".join(t).rstrip(\"\\n\") for t in shortened_dataset]\n",
        "generated_summaries = summarizer.predict(\n",
        "    shortened_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS\n",
        ")\n",
        "assert len(generated_summaries) == len(reference_summaries)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating summary:   0%|          | 0/32 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset length is 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5a1225987cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreference_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshortened_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m generated_summaries = summarizer.predict(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mshortened_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_GPUS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_summaries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_summaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils_nlp/models/transformers/abstractive_summarization_bertsum.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, num_gpus, gpu_ids, local_rank, batch_size, alpha, beam_size, min_length, max_length, fp16, verbose)\u001b[0m\n\u001b[1;32m    785\u001b[0m         ):\n\u001b[1;32m    786\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             \u001b[0mtranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mtranslations_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary_from_tokenid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils_nlp/models/transformers/bertsum/predictor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, segs, mask_src)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             predictions, scores = self._fast_translate_batch(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils_nlp/models/transformers/bertsum/predictor.py\u001b[0m in \u001b[0;36m_fast_translate_batch\u001b[0;34m(self, src, segs, mask_src, max_length, min_length)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;31m# Append last prediction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             alive_seq = torch.cat(\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0malive_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \"index_select_out_cuda_impl\" not implemented for 'Float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTpk3FrK8LtI",
        "outputId": "d4933861-5668-42d9-e1b4-f0e16eba2757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "generated_summaries = summarizer.predict(shortened_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating summary:   0%|          | 0/32 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset length is 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-abae5a885969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerated_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshortened_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_GPUS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/utils_nlp/models/transformers/abstractive_summarization_bertsum.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, num_gpus, gpu_ids, local_rank, batch_size, alpha, beam_size, min_length, max_length, fp16, verbose)\u001b[0m\n\u001b[1;32m    785\u001b[0m         ):\n\u001b[1;32m    786\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             \u001b[0mtranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mtranslations_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary_from_tokenid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils_nlp/models/transformers/bertsum/predictor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, segs, mask_src)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             predictions, scores = self._fast_translate_batch(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils_nlp/models/transformers/bertsum/predictor.py\u001b[0m in \u001b[0;36m_fast_translate_batch\u001b[0;34m(self, src, segs, mask_src, max_length, min_length)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;31m# Append last prediction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             alive_seq = torch.cat(\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0malive_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: index_select() received an invalid combination of arguments - got (float, Tensor), but expected one of:\n * (name dim, Tensor index)\n      didn't match because some of the arguments have invalid types: (!float!, Tensor)\n * (int dim, Tensor index)\n      didn't match because some of the arguments have invalid types: (!float!, Tensor)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekeeRnuV8Ygv"
      },
      "source": [
        "source = \"\"\"\n",
        "But under the new rule, set to be announced in the next 48 hours, Border Patrol agents would immediately return anyone to Mexico â€” without any detainment and without any due process â€” who attempts to cross the southwestern border between the legal ports of entry. The person would not be held for any length of time in an American facility.\n",
        "\n",
        "Although they advised that details could change before the announcement, administration officials said the measure was needed to avert what they fear could be a systemwide outbreak of the coronavirus inside detention facilities along the border. Such an outbreak could spread quickly through the immigrant population and could infect large numbers of Border Patrol agents, leaving the southwestern border defenses weakened, the officials argued.\n",
        "The Trump administration plans to immediately turn back all asylum seekers and other foreigners attempting to enter the United States from Mexico illegally, saying the nation cannot risk allowing the coronavirus to spread through detention facilities and Border Patrol agents, four administration officials said.\n",
        "The administration officials said the ports of entry would remain open to American citizens, green-card holders and foreigners with proper documentation. Some foreigners would be blocked, including Europeans currently subject to earlier travel restrictions imposed by the administration. The points of entry will also be open to commercial traffic.\"\"\"\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoSL9WmQCTzL",
        "outputId": "a325db0f-e7b5-4e53-a92e-76f1ed978293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "test_dataset = SummarizationDataset(\n",
        "    None, source=[source], source_preprocessing=[tokenize.sent_tokenize],\n",
        ")\n",
        "generated_summaries = summarizer.predict(test_dataset, batch_size=1, num_gpus=NUM_GPUS)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating summary:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset length is 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9d3af18c8428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_preprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerated_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_GPUS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/utils_nlp/models/transformers/abstractive_summarization_bertsum.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, num_gpus, gpu_ids, local_rank, batch_size, alpha, beam_size, min_length, max_length, fp16, verbose)\u001b[0m\n\u001b[1;32m    785\u001b[0m         ):\n\u001b[1;32m    786\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             \u001b[0mtranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mtranslations_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary_from_tokenid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils_nlp/models/transformers/bertsum/predictor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, segs, mask_src)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             predictions, scores = self._fast_translate_batch(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils_nlp/models/transformers/bertsum/predictor.py\u001b[0m in \u001b[0;36m_fast_translate_batch\u001b[0;34m(self, src, segs, mask_src, max_length, min_length)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;31m# Append last prediction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             alive_seq = torch.cat(\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0malive_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \"index_select_out_cuda_impl\" not implemented for 'Float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeW_ZNlECWYB",
        "outputId": "7d65b56c-9cfc-46c7-a69a-29f71b32a4b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip list"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Package                       Version       \n",
            "----------------------------- --------------\n",
            "absl-py                       0.12.0        \n",
            "alabaster                     0.7.12        \n",
            "albumentations                0.1.12        \n",
            "altair                        4.1.0         \n",
            "appdirs                       1.4.4         \n",
            "argon2-cffi                   20.1.0        \n",
            "astor                         0.8.1         \n",
            "astropy                       4.2.1         \n",
            "astunparse                    1.6.3         \n",
            "async-generator               1.10          \n",
            "atari-py                      0.2.6         \n",
            "atomicwrites                  1.4.0         \n",
            "attrs                         20.3.0        \n",
            "audioread                     2.1.9         \n",
            "autograd                      1.3           \n",
            "Babel                         2.9.0         \n",
            "backcall                      0.2.0         \n",
            "beautifulsoup4                4.6.3         \n",
            "bleach                        3.3.0         \n",
            "blis                          0.4.1         \n",
            "bokeh                         2.3.1         \n",
            "Bottleneck                    1.3.2         \n",
            "branca                        0.4.2         \n",
            "bs4                           0.0.1         \n",
            "CacheControl                  0.12.6        \n",
            "cachetools                    4.2.1         \n",
            "catalogue                     1.0.0         \n",
            "certifi                       2020.12.5     \n",
            "cffi                          1.14.5        \n",
            "chainer                       7.4.0         \n",
            "chardet                       3.0.4         \n",
            "click                         7.1.2         \n",
            "cloudpickle                   1.3.0         \n",
            "cmake                         3.12.0        \n",
            "cmdstanpy                     0.9.5         \n",
            "colorcet                      2.0.6         \n",
            "colorlover                    0.3.0         \n",
            "community                     1.0.0b1       \n",
            "contextlib2                   0.5.5         \n",
            "convertdate                   2.3.2         \n",
            "coverage                      3.7.1         \n",
            "coveralls                     0.5           \n",
            "crcmod                        1.7           \n",
            "cufflinks                     0.17.3        \n",
            "cvxopt                        1.2.6         \n",
            "cvxpy                         1.0.31        \n",
            "cycler                        0.10.0        \n",
            "cymem                         2.0.5         \n",
            "Cython                        0.29.22       \n",
            "daft                          0.0.4         \n",
            "dask                          2.12.0        \n",
            "datascience                   0.10.6        \n",
            "debugpy                       1.0.0         \n",
            "decorator                     4.4.2         \n",
            "defusedxml                    0.7.1         \n",
            "descartes                     1.1.0         \n",
            "dill                          0.3.3         \n",
            "distributed                   1.25.3        \n",
            "dlib                          19.18.0       \n",
            "dm-tree                       0.1.5         \n",
            "docopt                        0.6.2         \n",
            "docutils                      0.17          \n",
            "dopamine-rl                   1.0.5         \n",
            "earthengine-api               0.1.260       \n",
            "easydict                      1.9           \n",
            "ecos                          2.0.7.post1   \n",
            "editdistance                  0.5.3         \n",
            "en-core-web-sm                2.2.5         \n",
            "entrypoints                   0.3           \n",
            "ephem                         3.7.7.1       \n",
            "et-xmlfile                    1.0.1         \n",
            "fa2                           0.3.5         \n",
            "fancyimpute                   0.4.3         \n",
            "fastai                        1.0.61        \n",
            "fastdtw                       0.3.4         \n",
            "fastprogress                  1.0.0         \n",
            "fastrlock                     0.6           \n",
            "fbprophet                     0.7.1         \n",
            "feather-format                0.4.1         \n",
            "filelock                      3.0.12        \n",
            "firebase-admin                4.4.0         \n",
            "fix-yahoo-finance             0.0.22        \n",
            "Flask                         1.1.2         \n",
            "flatbuffers                   1.12          \n",
            "folium                        0.8.3         \n",
            "future                        0.16.0        \n",
            "gast                          0.3.3         \n",
            "GDAL                          2.2.2         \n",
            "gdown                         3.6.4         \n",
            "gensim                        3.6.0         \n",
            "geographiclib                 1.50          \n",
            "geopy                         1.17.0        \n",
            "gin-config                    0.4.0         \n",
            "glob2                         0.7           \n",
            "google                        2.0.3         \n",
            "google-api-core               1.26.3        \n",
            "google-api-python-client      1.12.8        \n",
            "google-auth                   1.28.1        \n",
            "google-auth-httplib2          0.0.4         \n",
            "google-auth-oauthlib          0.4.4         \n",
            "google-cloud-bigquery         1.21.0        \n",
            "google-cloud-bigquery-storage 1.1.0         \n",
            "google-cloud-core             1.0.3         \n",
            "google-cloud-datastore        1.8.0         \n",
            "google-cloud-firestore        1.7.0         \n",
            "google-cloud-language         1.2.0         \n",
            "google-cloud-storage          1.18.1        \n",
            "google-cloud-translate        1.5.0         \n",
            "google-colab                  1.0.0         \n",
            "google-pasta                  0.2.0         \n",
            "google-resumable-media        0.4.1         \n",
            "googleapis-common-protos      1.53.0        \n",
            "googledrivedownloader         0.4           \n",
            "graphviz                      0.10.1        \n",
            "greenlet                      1.0.0         \n",
            "grpcio                        1.32.0        \n",
            "gspread                       3.0.1         \n",
            "gspread-dataframe             3.0.8         \n",
            "gym                           0.17.3        \n",
            "h5py                          2.10.0        \n",
            "HeapDict                      1.0.1         \n",
            "hijri-converter               2.1.1         \n",
            "holidays                      0.10.5.2      \n",
            "holoviews                     1.14.3        \n",
            "html5lib                      1.0.1         \n",
            "httpimport                    0.5.18        \n",
            "httplib2                      0.17.4        \n",
            "httplib2shim                  0.0.3         \n",
            "humanize                      0.5.1         \n",
            "hyperopt                      0.1.2         \n",
            "ideep4py                      2.0.0.post3   \n",
            "idna                          2.10          \n",
            "imageio                       2.4.1         \n",
            "imagesize                     1.2.0         \n",
            "imbalanced-learn              0.4.3         \n",
            "imblearn                      0.0           \n",
            "imgaug                        0.2.9         \n",
            "importlib-metadata            3.10.0        \n",
            "importlib-resources           5.1.2         \n",
            "imutils                       0.5.4         \n",
            "inflect                       2.1.0         \n",
            "iniconfig                     1.1.1         \n",
            "intel-openmp                  2021.2.0      \n",
            "intervaltree                  2.1.0         \n",
            "ipykernel                     4.10.1        \n",
            "ipython                       5.5.0         \n",
            "ipython-genutils              0.2.0         \n",
            "ipython-sql                   0.3.9         \n",
            "ipywidgets                    7.6.3         \n",
            "itsdangerous                  1.1.0         \n",
            "jax                           0.2.12        \n",
            "jaxlib                        0.1.65+cuda110\n",
            "jdcal                         1.4.1         \n",
            "jedi                          0.18.0        \n",
            "jieba                         0.42.1        \n",
            "Jinja2                        2.11.3        \n",
            "joblib                        1.0.1         \n",
            "jpeg4py                       0.1.4         \n",
            "jsonschema                    2.6.0         \n",
            "jupyter                       1.0.0         \n",
            "jupyter-client                5.3.5         \n",
            "jupyter-console               5.2.0         \n",
            "jupyter-core                  4.7.1         \n",
            "jupyterlab-pygments           0.1.2         \n",
            "jupyterlab-widgets            1.0.0         \n",
            "kaggle                        1.5.12        \n",
            "kapre                         0.1.3.1       \n",
            "Keras                         2.4.3         \n",
            "Keras-Preprocessing           1.1.2         \n",
            "keras-vis                     0.4.1         \n",
            "kiwisolver                    1.3.1         \n",
            "knnimpute                     0.1.0         \n",
            "korean-lunar-calendar         0.2.1         \n",
            "librosa                       0.8.0         \n",
            "lightgbm                      2.2.3         \n",
            "llvmlite                      0.34.0        \n",
            "lmdb                          0.99          \n",
            "LunarCalendar                 0.0.9         \n",
            "lxml                          4.2.6         \n",
            "Markdown                      3.3.4         \n",
            "MarkupSafe                    1.1.1         \n",
            "matplotlib                    3.2.2         \n",
            "matplotlib-venn               0.11.6        \n",
            "missingno                     0.4.2         \n",
            "mistune                       0.8.4         \n",
            "mizani                        0.6.0         \n",
            "mkl                           2019.0        \n",
            "mlxtend                       0.14.0        \n",
            "more-itertools                8.7.0         \n",
            "moviepy                       0.2.3.5       \n",
            "mpmath                        1.2.1         \n",
            "msgpack                       1.0.2         \n",
            "multiprocess                  0.70.11.1     \n",
            "multitasking                  0.0.9         \n",
            "murmurhash                    1.0.5         \n",
            "music21                       5.5.0         \n",
            "natsort                       5.5.0         \n",
            "nbclient                      0.5.3         \n",
            "nbconvert                     5.6.1         \n",
            "nbformat                      5.1.3         \n",
            "nest-asyncio                  1.5.1         \n",
            "networkx                      2.5.1         \n",
            "nibabel                       3.0.2         \n",
            "nltk                          3.2.5         \n",
            "notebook                      5.3.1         \n",
            "np-utils                      0.5.12.1      \n",
            "numba                         0.51.2        \n",
            "numexpr                       2.7.3         \n",
            "numpy                         1.19.5        \n",
            "nvidia-ml-py3                 7.352.0       \n",
            "oauth2client                  4.1.3         \n",
            "oauthlib                      3.1.0         \n",
            "okgrade                       0.4.3         \n",
            "opencv-contrib-python         4.1.2.30      \n",
            "opencv-python                 4.1.2.30      \n",
            "openpyxl                      2.5.9         \n",
            "opt-einsum                    3.3.0         \n",
            "osqp                          0.6.2.post0   \n",
            "packaging                     20.9          \n",
            "palettable                    3.3.0         \n",
            "pandas                        1.1.5         \n",
            "pandas-datareader             0.9.0         \n",
            "pandas-gbq                    0.13.3        \n",
            "pandas-profiling              1.4.1         \n",
            "pandocfilters                 1.4.3         \n",
            "panel                         0.11.1        \n",
            "param                         1.10.1        \n",
            "parso                         0.8.2         \n",
            "pathlib                       1.0.1         \n",
            "patsy                         0.5.1         \n",
            "pexpect                       4.8.0         \n",
            "pickleshare                   0.7.5         \n",
            "Pillow                        7.1.2         \n",
            "pip                           19.3.1        \n",
            "pip-tools                     4.5.1         \n",
            "plac                          1.1.3         \n",
            "plotly                        4.4.1         \n",
            "plotnine                      0.6.0         \n",
            "pluggy                        0.7.1         \n",
            "pooch                         1.3.0         \n",
            "portpicker                    1.3.1         \n",
            "prefetch-generator            1.0.1         \n",
            "preshed                       3.0.5         \n",
            "prettytable                   2.1.0         \n",
            "progressbar2                  3.38.0        \n",
            "prometheus-client             0.10.1        \n",
            "promise                       2.3           \n",
            "prompt-toolkit                1.0.18        \n",
            "protobuf                      3.12.4        \n",
            "psutil                        5.4.8         \n",
            "psycopg2                      2.7.6.1       \n",
            "ptyprocess                    0.7.0         \n",
            "py                            1.10.0        \n",
            "pyarrow                       3.0.0         \n",
            "pyasn1                        0.4.8         \n",
            "pyasn1-modules                0.2.8         \n",
            "pycocotools                   2.0.2         \n",
            "pycparser                     2.20          \n",
            "pyct                          0.4.8         \n",
            "pydata-google-auth            1.1.0         \n",
            "pydot                         1.3.0         \n",
            "pydot-ng                      2.0.0         \n",
            "pydotplus                     2.0.2         \n",
            "PyDrive                       1.3.1         \n",
            "pyemd                         0.5.1         \n",
            "pyerfa                        1.7.2         \n",
            "pyglet                        1.5.0         \n",
            "Pygments                      2.6.1         \n",
            "pygobject                     3.26.1        \n",
            "pymc3                         3.7           \n",
            "PyMeeus                       0.5.11        \n",
            "pymongo                       3.11.3        \n",
            "pymystem3                     0.2.0         \n",
            "PyOpenGL                      3.1.5         \n",
            "pyparsing                     2.4.7         \n",
            "pyrsistent                    0.17.3        \n",
            "pysndfile                     1.3.8         \n",
            "PySocks                       1.7.1         \n",
            "pystan                        2.19.1.1      \n",
            "pytest                        3.6.4         \n",
            "python-apt                    0.0.0         \n",
            "python-chess                  0.23.11       \n",
            "python-dateutil               2.8.1         \n",
            "python-louvain                0.15          \n",
            "python-slugify                4.0.1         \n",
            "python-utils                  2.5.6         \n",
            "pytz                          2018.9        \n",
            "pyviz-comms                   2.0.1         \n",
            "PyWavelets                    1.1.1         \n",
            "PyYAML                        3.13          \n",
            "pyzmq                         22.0.3        \n",
            "qdldl                         0.1.5.post0   \n",
            "qtconsole                     5.0.3         \n",
            "QtPy                          1.9.0         \n",
            "regex                         2019.12.20    \n",
            "requests                      2.23.0        \n",
            "requests-oauthlib             1.3.0         \n",
            "resampy                       0.2.2         \n",
            "retrying                      1.3.3         \n",
            "rpy2                          3.4.3         \n",
            "rsa                           4.7.2         \n",
            "scikit-image                  0.16.2        \n",
            "scikit-learn                  0.22.2.post1  \n",
            "scipy                         1.4.1         \n",
            "screen-resolution-extra       0.0.0         \n",
            "scs                           2.1.2         \n",
            "seaborn                       0.11.1        \n",
            "Send2Trash                    1.5.0         \n",
            "setuptools                    54.2.0        \n",
            "setuptools-git                1.2           \n",
            "Shapely                       1.7.1         \n",
            "simplegeneric                 0.8.1         \n",
            "six                           1.15.0        \n",
            "sklearn                       0.0           \n",
            "sklearn-pandas                1.8.0         \n",
            "smart-open                    5.0.0         \n",
            "snowballstemmer               2.1.0         \n",
            "sortedcontainers              2.3.0         \n",
            "SoundFile                     0.10.3.post1  \n",
            "spacy                         2.2.4         \n",
            "Sphinx                        1.8.5         \n",
            "sphinxcontrib-serializinghtml 1.1.4         \n",
            "sphinxcontrib-websupport      1.2.4         \n",
            "SQLAlchemy                    1.4.6         \n",
            "sqlparse                      0.4.1         \n",
            "srsly                         1.0.5         \n",
            "statsmodels                   0.10.2        \n",
            "sympy                         1.7.1         \n",
            "tables                        3.4.4         \n",
            "tabulate                      0.8.9         \n",
            "tblib                         1.7.0         \n",
            "tensorboard                   2.4.1         \n",
            "tensorboard-plugin-wit        1.8.0         \n",
            "tensorflow                    2.4.1         \n",
            "tensorflow-datasets           4.0.1         \n",
            "tensorflow-estimator          2.4.0         \n",
            "tensorflow-gcs-config         2.4.0         \n",
            "tensorflow-hub                0.11.0        \n",
            "tensorflow-metadata           0.29.0        \n",
            "tensorflow-probability        0.12.1        \n",
            "termcolor                     1.1.0         \n",
            "terminado                     0.9.4         \n",
            "testpath                      0.4.4         \n",
            "text-unidecode                1.3           \n",
            "textblob                      0.15.3        \n",
            "textgenrnn                    1.4.1         \n",
            "Theano                        1.0.5         \n",
            "thinc                         7.4.0         \n",
            "tifffile                      2021.4.8      \n",
            "toml                          0.10.2        \n",
            "toolz                         0.11.1        \n",
            "torch                         1.8.1+cu101   \n",
            "torchsummary                  1.5.1         \n",
            "torchtext                     0.9.1         \n",
            "torchvision                   0.9.1+cu101   \n",
            "tornado                       5.1.1         \n",
            "tqdm                          4.41.1        \n",
            "traitlets                     5.0.5         \n",
            "tweepy                        3.10.0        \n",
            "typeguard                     2.7.1         \n",
            "typing-extensions             3.7.4.3       \n",
            "tzlocal                       1.5.1         \n",
            "uritemplate                   3.0.1         \n",
            "urllib3                       1.24.3        \n",
            "vega-datasets                 0.9.0         \n",
            "wasabi                        0.8.2         \n",
            "wcwidth                       0.2.5         \n",
            "webencodings                  0.5.1         \n",
            "Werkzeug                      1.0.1         \n",
            "wheel                         0.36.2        \n",
            "widgetsnbextension            3.5.1         \n",
            "wordcloud                     1.5.0         \n",
            "wrapt                         1.12.1        \n",
            "xarray                        0.15.1        \n",
            "xgboost                       0.90          \n",
            "xkit                          0.0.0         \n",
            "xlrd                          1.1.0         \n",
            "xlwt                          1.3.0         \n",
            "yellowbrick                   0.9.1         \n",
            "zict                          2.0.0         \n",
            "zipp                          3.4.1         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIn3MmBVXyDy",
        "outputId": "c752256c-6d3a-4af4-e263-03a2c92e5c16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install torch==1.4.0 torchvision==0.5.0 -f https://download.pytorch.org/whl/cu101/torch_stable.html"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 753.4MB 20kB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/torchvision/\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.0MB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkAljOkDzw2t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}